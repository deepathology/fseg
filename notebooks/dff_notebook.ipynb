{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "token = \"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\"\n",
    "login(token=token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: torch.Size([1, 1536, 60, 60])\n",
      "activations before transpose (1, 1536, 60, 60)\n",
      "activations (60, 60, 1536)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Array with wrong shape passed to NMF (input H). Expected (64, 3600), but got (1536, 64) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 82\u001b[0m\n\u001b[1;32m     73\u001b[0m unsupervised_seg \u001b[39m=\u001b[39m DFFSeg(\n\u001b[1;32m     74\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     75\u001b[0m     target_layer\u001b[39m=\u001b[39mtarget_layer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     concepts\u001b[39m=\u001b[39mconcepts\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     81\u001b[0m \u001b[39m#unsupervised_seg.partial_fit(input_tensor=input_tensor)\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m segmentation \u001b[39m=\u001b[39m unsupervised_seg\u001b[39m.\u001b[39;49mpredict(input_tensor\u001b[39m=\u001b[39;49minput_tensor)\n\u001b[1;32m     83\u001b[0m visualization \u001b[39m=\u001b[39m show_segmentation_on_image(\n\u001b[1;32m     84\u001b[0m     img\u001b[39m=\u001b[39mimg,\n\u001b[1;32m     85\u001b[0m     segmentation\u001b[39m=\u001b[39msegmentation,\n\u001b[1;32m     86\u001b[0m     image_weight\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m,\n\u001b[1;32m     87\u001b[0m     n_categories\u001b[39m=\u001b[39mnum_concepts)\n\u001b[1;32m     90\u001b[0m segmentation2 \u001b[39m=\u001b[39m unsupervised_seg\u001b[39m.\u001b[39mpredict(input_tensor\u001b[39m=\u001b[39minput_tensor2)\n",
      "File \u001b[0;32m~/dev/dff_seg/dff_seg/dff_seg.py:213\u001b[0m, in \u001b[0;36mDFFSeg.predict\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m    211\u001b[0m vector \u001b[39m=\u001b[39m activations\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, activations\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    212\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mactivations\u001b[39m\u001b[39m\"\u001b[39m, activations\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 213\u001b[0m w, __, __ \u001b[39m=\u001b[39m non_negative_factorization(\n\u001b[1;32m    214\u001b[0m     X\u001b[39m=\u001b[39;49mvector\u001b[39m.\u001b[39;49mtranspose(),\n\u001b[1;32m    215\u001b[0m     H\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconcepts,\n\u001b[1;32m    216\u001b[0m     W\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    217\u001b[0m     n_components\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_concepts,\n\u001b[1;32m    218\u001b[0m     update_H\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    219\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m    220\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m,\n\u001b[1;32m    221\u001b[0m )\n\u001b[1;32m    223\u001b[0m w \u001b[39m=\u001b[39m w\u001b[39m.\u001b[39mreshape((activations\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], activations\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    224\u001b[0m w_for_resize \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m    225\u001b[0m     w\u001b[39m.\u001b[39mtranspose(\n\u001b[1;32m    226\u001b[0m         (\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))[\n\u001b[1;32m    227\u001b[0m         \u001b[39mNone\u001b[39;00m, :, :, :])  \u001b[39m# Add batch dimension\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1153\u001b[0m, in \u001b[0;36mnon_negative_factorization\u001b[0;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, alpha_W, alpha_H, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[1;32m   1135\u001b[0m est \u001b[39m=\u001b[39m NMF(\n\u001b[1;32m   1136\u001b[0m     n_components\u001b[39m=\u001b[39mn_components,\n\u001b[1;32m   1137\u001b[0m     init\u001b[39m=\u001b[39minit,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     regularization\u001b[39m=\u001b[39mregularization,\n\u001b[1;32m   1150\u001b[0m )\n\u001b[1;32m   1152\u001b[0m \u001b[39mwith\u001b[39;00m config_context(assume_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m-> 1153\u001b[0m     W, H, n_iter \u001b[39m=\u001b[39m est\u001b[39m.\u001b[39;49m_fit_transform(X, W\u001b[39m=\u001b[39;49mW, H\u001b[39m=\u001b[39;49mH, update_H\u001b[39m=\u001b[39;49mupdate_H)\n\u001b[1;32m   1155\u001b[0m \u001b[39mreturn\u001b[39;00m W, H, n_iter\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1652\u001b[0m, in \u001b[0;36mNMF._fit_transform\u001b[0;34m(self, X, y, W, H, update_H)\u001b[0m\n\u001b[1;32m   1645\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1646\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen beta_loss <= 0 and X contains zeros, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1647\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe solver may diverge. Please add small values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1648\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto X, or use a positive beta_loss.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1649\u001b[0m     )\n\u001b[1;32m   1651\u001b[0m \u001b[39m# initialize or check W and H\u001b[39;00m\n\u001b[0;32m-> 1652\u001b[0m W, H \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_w_h(X, W, H, update_H)\n\u001b[1;32m   1654\u001b[0m \u001b[39m# scale the regularization terms\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scale_regularization(X)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1525\u001b[0m, in \u001b[0;36mNMF._check_w_h\u001b[0;34m(self, X, W, H, update_H)\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1521\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mH and W should have the same dtype as X. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1522\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mH.dtype = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and W.dtype = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(H\u001b[39m.\u001b[39mdtype, W\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   1523\u001b[0m         )\n\u001b[1;32m   1524\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m update_H:\n\u001b[0;32m-> 1525\u001b[0m     _check_init(H, (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_components, n_features), \u001b[39m\"\u001b[39;49m\u001b[39mNMF (input H)\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1526\u001b[0m     \u001b[39mif\u001b[39;00m H\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m X\u001b[39m.\u001b[39mdtype:\n\u001b[1;32m   1527\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1528\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mH should have the same dtype as X. Got H.dtype = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1529\u001b[0m                 H\u001b[39m.\u001b[39mdtype\n\u001b[1;32m   1530\u001b[0m             )\n\u001b[1;32m   1531\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:61\u001b[0m, in \u001b[0;36m_check_init\u001b[0;34m(A, shape, whom)\u001b[0m\n\u001b[1;32m     59\u001b[0m A \u001b[39m=\u001b[39m check_array(A)\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mshape(A) \u001b[39m!=\u001b[39m shape:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     62\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mArray with wrong shape passed to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Expected \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m         \u001b[39m%\u001b[39m (whom, shape, np\u001b[39m.\u001b[39mshape(A))\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m check_non_negative(A, whom)\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmax(A) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Array with wrong shape passed to NMF (input H). Expected (64, 3600), but got (1536, 64) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import dff_seg.dff_seg\n",
    "importlib.reload(dff_seg.dff_seg)\n",
    "from dff_seg.dff_seg import DFFSeg, show_segmentation_on_image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam.utils.image import preprocess_image\n",
    "from torchvision.models import resnet50\n",
    "from functools import partial\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "def uni_model_transform(tensor, width, height):\n",
    "    result = torch.nn.ReLU()(tensor[:, 1:, :].reshape(tensor.size(0),\n",
    "                            height,\n",
    "                            width,\n",
    "                            tensor.size(2)))\n",
    "    # Bring the channels to the first dimension,\n",
    "    # like in CNNs.\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    print(f\"result: {result.shape}\")\n",
    "    return result\n",
    "\n",
    "num_concepts = 20\n",
    "img_path = r\"/home/gildenbj/a.png\"\n",
    "img = np.array(Image.open(img_path))\n",
    "img = img[:16*(img.shape[0] // 16), :16*(img.shape[1] // 16), :]\n",
    "img = img[:1024-64, :1024-64, :]\n",
    "rgb_img_float = np.float32(img) / 255\n",
    "input_tensor = preprocess_image(rgb_img_float,\n",
    "                                mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "img_path2 = r\"/home/gildenbj/b.png\"\n",
    "img2 = np.array(Image.open(img_path2))\n",
    "#img2 = img2[:16*(img2.shape[0] // 16), :16*(img2.shape[1] // 16), :]\n",
    "img2 = img2[:1024-64, :1024-64, :]\n",
    "rgb_img_float2 = np.float32(img2) / 255\n",
    "input_tensor2 = preprocess_image(rgb_img_float2,\n",
    "                                mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "model_name = \"gigapath\"\n",
    "\n",
    "if model_name == \"gigapath\":\n",
    "    model = timm.create_model(\"hf_hub:prov-gigapath/prov-gigapath\", pretrained=True, dynamic_img_size=True)\n",
    "    target_layer = model.blocks[-1]\n",
    "    concepts = np.load(\"/home/gildenbj/dev/dff_seg/concepts_gigapath_concepts.npy\")\n",
    "\n",
    "    num_concepts = concepts.shape[0]\n",
    "if model_name == \"resnet50\":\n",
    "    concepts = np.load(\"/home/gildenbj/dev/dff_seg/concepts_resnet50_concepts.npy\")\n",
    "    num_concepts = concepts.shape[0]\n",
    "    model = resnet50(pretrained=True)\n",
    "    target_layer = model.layer4\n",
    "    reshape_transform = None\n",
    "elif model_name == \"uni\":\n",
    "    concepts = np.load(\"/home/gildenbj/dev/dff_seg/concepts_uni_concepts.npy\")\n",
    "    num_concepts = concepts.shape[0]\n",
    "    model = timm.create_model(\"hf-hub:MahmoodLab/uni\", pretrained=True, init_values=1e-5, dynamic_img_size=True)\n",
    "    target_layer = model.blocks[-1]\n",
    "    reshape_transform = partial(\n",
    "        uni_model_transform,\n",
    "        width=input_tensor.shape[3]//16,\n",
    "        height=input_tensor.shape[2]//16,\n",
    "    )\n",
    "    \n",
    "model.eval()\n",
    "unsupervised_seg = DFFSeg(\n",
    "    model=model,\n",
    "    target_layer=target_layer,\n",
    "    n_concepts=num_concepts,\n",
    "    reshape_transform=reshape_transform,\n",
    "    concepts=concepts\n",
    ")\n",
    "\n",
    "#unsupervised_seg.partial_fit(input_tensor=input_tensor)\n",
    "segmentation = unsupervised_seg.predict(input_tensor=input_tensor)\n",
    "visualization = show_segmentation_on_image(\n",
    "    img=img,\n",
    "    segmentation=segmentation,\n",
    "    image_weight=0.7,\n",
    "    n_categories=num_concepts)\n",
    "\n",
    "\n",
    "segmentation2 = unsupervised_seg.predict(input_tensor=input_tensor2)\n",
    "visualization2 = show_segmentation_on_image(\n",
    "    img=img2,\n",
    "    segmentation=segmentation2,\n",
    "    image_weight=0.7,\n",
    "    n_categories=num_concepts)\n",
    "display(Image.fromarray(visualization))\n",
    "display(Image.fromarray(visualization2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
